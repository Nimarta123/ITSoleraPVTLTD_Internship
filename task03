import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.tsa.arima.model import ARIMA
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error

# 1. Load and Preprocess Data
# We handle '?' as NaN and combine Date/Time into a single index
df = pd.read_csv('household_power_consumption.csv', na_values='?', low_memory=False)
df['Datetime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], dayfirst=True)
df = df.set_index('Datetime')
df = df.drop(['Date', 'Time'], axis=1)

# 2. Resample Data
# Resampling to Daily (sum) to capture long-term patterns and speed up processing
daily_df = df['Global_active_power'].resample('D').sum().dropna()

# 3. Feature Engineering (for Machine Learning Models)
def create_features(df_series):
    df_feat = pd.DataFrame(index=df_series.index)
    df_feat['Global_active_power'] = df_series.values
    df_feat['day_of_week'] = df_feat.index.dayofweek
    df_feat['month'] = df_feat.index.month
    df_feat['is_weekend'] = df_feat.index.dayofweek.isin([5, 6]).astype(int)
    
    # Lag features: Using past 7 days to predict today
    for i in range(1, 8):
        df_feat[f'lag_{i}'] = df_feat['Global_active_power'].shift(i)
        
    return df_feat.dropna()

model_df = create_features(daily_df)

# 4. Train/Test Split
# We use the last 30 days for testing
test_days = 30
train_data = model_df.iloc[:-test_days]
test_data = model_df.iloc[-test_days:]

X_train, y_train = train_data.drop('Global_active_power', axis=1), train_data['Global_active_power']
X_test, y_test = test_data.drop('Global_active_power', axis=1), test_data['Global_active_power']

# 5. Model Training
# A. ARIMA Model (Statistical approach)
train_series = daily_df.iloc[:-(test_days)]
arima_model = ARIMA(train_series, order=(5, 1, 0)) # p,d,q parameters
arima_fit = arima_model.fit()
arima_forecast = arima_fit.forecast(steps=test_days)

# B. Random Forest Model (ML approach - Proxy for XGBoost)
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
rf_preds = rf_model.predict(X_test)

# 6. Evaluation and Comparison
def evaluate(actual, pred, name):
    mae = mean_absolute_error(actual, pred)
    rmse = np.sqrt(mean_squared_error(actual, pred))
    print(f"{name} -> MAE: {mae:.2f}, RMSE: {rmse:.2f}")

evaluate(y_test, arima_forecast, "ARIMA")
evaluate(y_test, rf_preds, "Random Forest")

# 7. Visualization
plt.figure(figsize=(12, 6))
plt.plot(test_data.index, y_test, label='Actual Usage', color='black', linewidth=2)
plt.plot(test_data.index, arima_forecast, label='ARIMA Forecast', linestyle='--')
plt.plot(test_data.index, rf_preds, label='Random Forest Forecast', linestyle='-.')
plt.title('Daily Energy Consumption Forecast Comparison')
plt.xlabel('Date')
plt.ylabel('Global Active Power')
plt.legend()
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()
